% File: design.tex
% Date: 8.27.2014
% Author: Jared Bold

% Section Name
\chapter{Design}

% Common Design Components
\section{Common Design Components}

% Image format
\subsection{Tagged Image File Format}
All images used throughout this research are Tagged Image File Format (TIFF) images. TIFF images consist of an image header that describes the byte order, TIFF version number, and offset to the image file directory\cite{Wiggins2001}.  The image file directory stores the offsets to the directory entries and varies in size based on the number of images contained within the TIFF image.  The directory entry is then broken down into several sections including a Tag section which consists of a number of tags which give information about the image including the bits per pixel, compression scheme, image length and height, and many more.  The directory entry is lastly completed with the offset to the image data. Figure \ref{fig:tiffFormat} shows a more in-depth representation of the TIFF structure for multiple image TIFFs.

\begin{figure}
  \centering
  \includegraphics[width=10cm]{./img/tiffFormat.png}
  \caption{TIFF File Structure\cite{Murray1996}}
  \label{fig:tiffFormat}
\end{figure}

For the purposes of this research, only uncompressed TIFF images are used in order to eliminate the need for resource intensive decompression and compression of input and output images.  To support the reading and writing of these image files, the LibTiff library is cross-compiled for use on the ZC702's PetaLinux OS. 

\subsection{User Interface}
A common user interface (UI) was developed for each algorithm in order to maintain continuity as well as ease development.  The UI shown in figure \ref{fig:ui} is used to fully test, validate, and exercise the C and hardware implementations of the 3x3 Gaussian blur filter.  The UIs for the 9x9 Laplacian of Gaussian filter and bilinear interpolation algorithms are identical with the exception of the title shown above the selection options.  From the UI, the user is prompted with an option selection; which based on the input performs different operations.  Selection option 1 runs the C version of the algorithm only, displays the runtime of a single run of the algorithm, and also outputs the resulting output image to a TIFF image file.  Selecting option 2 runs the hardware version of the algorithm, displays the runtime of a single run of the algorithm in hardware, and also outputs the resulting output image to a TIFF image file.  Selecting option 3 runs both the C and hardware versions of the algorithm and compares the outputs pixel by pixel.  This is used to verify that the hardware implementation yields an identical output as the software algorithm.  Depending on the algorithm, border pixels may be ignored due to the use of uninitialized values resulting in inconsistencies not only between the hardware and software implementations, but also between runs in these regions.  Selecting option 4 performs the C and hardware implementations 500 times and displays the average runtimes for each.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/research_ui.png}
  \caption{User Interface}
  \label{fig:ui}
\end{figure}

\subsection{PS/PL Transfer and Communication}
In order to facilitate the offloading of processing form the PS to the PL, the Xilinx AXI Direct Memory Access (DMA) IP was used.  This IP allowed for the PS to configure transactions between the DDR memory and the PL in both the read and write directions.  The AXI DMA, when instantiated in the PL, becomes a memory mapped peripheral that can be accessed from with the kernel space of the PS.  In order to access this memory, two approaches can be used.  The first is to write a device driver to configure and execute the memory transactions form the kernel space.  This approach has the benefit of being able to utilize many kernel space functionalities and features that are not available in the user space to more easily interace with the DMA.  However, the downside of this approach is that the time and understanding required to develop such a driver is quite extensive and is not within the scope of these experiments.  Instead, a user space driver was developed that enables user space applications to directly access the memory mapped address space of the DMA.  This access is accomplished using the mmap Linux function that maps a kernel space address to a user space address directly.  Using this method, the control and status registers of the AXI DMA can be directly read and modified with limited development time required.

The AXI DMA relies on physically contiguous memory for transactions.  When using a device driver, this memory can be allocated within the kernel space and guarenteed to be contiguous.  However, since a user space driver was used, this memory must be set aside when the Linux operating system boots.  To do so, the Linux device tree file is modified to limit the address space available to the operating system from 0x0 to 0x39000000, or 912 MB.  This leaves the address range of 0x39000001 to 0x40000000 to be used as a contiguous memory space for storing the data to be transferred into and out of the PL.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/generic_hard_soft_framework.png}
  \caption{Software framework for offloading using AXI DMA and developed library}
  \label{fig:generic_hard_soft_framework}
\end{figure}

To ease the development of applications that require the use of the AXI DMA and the pre-allocated contiguous address space, a C based libary was developed.  This library provides the ability to initialize and reset the AXI DMA IP, allocate contiguous memory with the pre-allocated space for the storage of input and output data, as well as to iniate both synchronus and asynchronous DMA transactions.  Using these library functions, a generic method of transferring data between the PS and PL was accomplished and adaptable to a number of different offloading operations.  Figure \ref{fig:generic_hard_soft_framework} shows the generic framework in which these library functions would be used.  This process was used in the development of the image filtering PL based designs as well as the bilinear interoplation homogeneous design.

\section{Processor Based Design}

\subsection{Image Filter}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/filter_software_framework.png}
  \caption{Processor based filter framework}
  \label{fig:filter_soft_framework}
\end{figure}

For this experiment, two filter kernels are used.  The first is a 3x3 Gaussian blur filter and the second is a 9x9 Laplacian of Gaussian (LoG) filter.  The framework in the processor based design is the same for both of these kernels as shown in Figure \ref{fig:filter_soft_framework}.  The processing occurs in the following steps:
\begin{enumerate}
  \item Read in the TIFF input image from the file system
  \item Allocate the output image in memory
  \item Perform the filtering by applying the filter kernel pixel by pixel, iterating over the entire image
  \item Convert the output image to the TIFF specification
  \item Write the TIFF output image to the file system
\end{enumerate}

Since the Linux operating system is used, the Zynq device provides a static file system that is used to store the input and output images.  This file system eliminates the need to transmit the processed image back to a host machine for storage.

\subsubsection{3x3 Gaussian Blur Filter}
\begin{figure}[h]
  \centering
  \includegraphics{./img/filter_3x3_values.PNG}
  \caption{3x3 Gaussian blur filter kernel}
  \label{fig:3x3_filter}
\end{figure}

The 3x3 Gaussian blur filter used in this experiment is shown in Figure \ref{fig:3x3_filter}. The filter acts as smoothing filter, removing some of the higher spatial frequencies present in the image and has a blurring effect.  The scale factor in front of the filter normalizes the filter so that there is no overall gain in the output image.

\subsubsection{9x9 Laplacian of Gaussian Filter}
\begin{figure}[h]
  \centering
  \includegraphics{./img/filter_9x9_values.PNG}
  \caption{9x9 LoG filter kernel}
  \label{fig:9x9_filter}
\end{figure}

The 9x9 LoG filter used in this experiment is shown in \ref{fig:9x9_filter}.  The filter is the equivalent of applying a Gaussian smoothing filter followed by a Laplacian high pass filter to an input image.  The reason that this is typically employed is to reduce the noise in an image using the smoothing filter and then to extract the edges within the image using the high pass filter.  Since the output image is high pass filtered, the mean value (DC component) is removed and the resulting output can be either a positive or negative number that would be unable to be displayed in a standard image format.  To resolve this issue, each output pixel is offset by 128 in order to remove any negative numbers.  Unlike the Gaussian blur filter, there is no need for a scale factor when applying the LoG filter because all of the coefficients sum to 0.

\subsection{Bilinear Interpolation}
\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/bilinear_software_framework.png}
  \caption{Bilinear interpolation algorithm software framework}
  \label{fig:bilinear_software}
\end{figure}

The implementation of the processor based bilinear interpolation algorithm used in this experiment is implemented using the separated version of the bilinear interpolator and a scale factor held constant at 2.  In this case, horizontal interpolation is first performed, followed by a vertical interpolation of the horizontally interpolated image.  The reason that the separated version of the algorithm was selected was to ease the process of developing a hardware co-design for offloading one of the interpolation stages.  Due to the necessity of processing the intermediate image, two memory allocations are required.  The first is used to temporarily store the horizontally interpolated image an dis used a the input for the vertical interpolator.  The second memory allocation store the output image.  Figure \ref{fig:bilinear_software} shows the framework used to perform the bilinear interpolation.  The processing of an image occurs in the following steps:

\begin{enumerate}
  \item Read in the TIFF input image from the file system
  \item Allocate the temporary image in memory
  \item Perform the horizontal bilinear interpolation
  \item Allocate the output image in memory
  \item Perform the vertical bilinear interpolation on the temporary image
  \item Convert the output image to the TIFF specification
  \item Write the TIFF output image to the file system
\end{enumerate}


\section{Programmable Logic Based Design - Image Filter}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/filter_hardware_software_framework.png}
  \caption{Software framework for hardware filter}
  \label{fig:hardware_software_framework}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/filter_hardware_framework.png}
  \caption{Hardware framework for filter}
  \label{fig:hardware_framework}
\end{figure}

\subsection{3x3 Gaussian Blur Filter}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./img/hardware_filter_3x3.png}
  \caption{Hardware implementation of 3x3 filter}
  \label{fig:hardware_3x3}
\end{figure}
\subsection{9x9 Laplacian of Gaussian Filter}

\section{Homogeneous Design}
\subsection{Bilinear Interpolation}

